{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhIgGq3za0yh"
      },
      "source": [
        "# A Diffusion Model from Scratch in Pytorch\n",
        "\n",
        "In this notebook I want to build a very simple (as few code as possible) Diffusion Model for generating car images. I will explain all the theoretical details in the YouTube video. \n",
        "\n",
        "\n",
        "**Sources:**\n",
        "- Github implementation [Denoising Diffusion Pytorch](https://github.com/lucidrains/denoising-diffusion-pytorch)\n",
        "- Niels Rogge, Kashif Rasul, [Huggingface notebook](https://colab.research.google.com/github/huggingface/notebooks/blob/main/examples/annotated_diffusion.ipynb#scrollTo=3a159023)\n",
        "- Papers on Diffusion models ([Dhariwal, Nichol, 2021], [Ho et al., 2020] ect.)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZF7wH4cE_JKY"
      },
      "source": [
        "# Building the Diffusion Model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rj17psVw7Shg"
      },
      "source": [
        "## Step 1: The forward process = Noise scheduler\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqcoJ8ZlXE1i"
      },
      "source": [
        "We first need to build the inputs for our model, which are more and more noisy images. Instead of doing this sequentially, we can use the closed form provided in the papers to calculate the image for any of the timesteps individually. \n",
        "\n",
        "**Key Takeaways**:\n",
        "- The noise-levels/variances can be pre-computed\n",
        "- There are different types of variance schedules\n",
        "- We can sample each timestep image independently (Sums of Gaussians is also Gaussian)\n",
        "- No model is needed in this forward step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qWw50ui9IZ5q"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/nfs/home/leo0511/CCBDA/HW3/CCBDA_HW3env/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from pytorch_gan_metrics import get_fid\n",
        "from torchvision.io import read_image\n",
        "device = \"cuda:3\"\n",
        "\n",
        "def linear_beta_schedule(timesteps, start=0.0001, end=0.02):\n",
        "    return torch.linspace(start, end, timesteps)\n",
        "\n",
        "def get_index_from_list(vals, t, x_shape):\n",
        "    \"\"\" \n",
        "    Returns a specific index t of a passed list of values vals\n",
        "    while considering the batch dimension.\n",
        "    \"\"\"\n",
        "    batch_size = t.shape[0]\n",
        "    out = vals.gather(-1, t.cpu())\n",
        "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1))).to(t.device)\n",
        "\n",
        "def forward_diffusion_sample(x_0, t, device=\"cpu\"):\n",
        "    \"\"\" \n",
        "    Takes an image and a timestep as input and \n",
        "    returns the noisy version of it\n",
        "    \"\"\"\n",
        "    noise = torch.randn_like(x_0)\n",
        "    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x_0.shape\n",
        "    )\n",
        "    # mean + variance\n",
        "    return sqrt_alphas_cumprod_t.to(device) * x_0.to(device) \\\n",
        "    + sqrt_one_minus_alphas_cumprod_t.to(device) * noise.to(device), noise.to(device)\n",
        "\n",
        "\n",
        "# Define beta schedule\n",
        "T = 1000\n",
        "betas = linear_beta_schedule(timesteps=T)\n",
        "\n",
        "# Pre-calculate different terms for closed form\n",
        "alphas = 1. - betas\n",
        "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
        "alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)\n",
        "sqrt_recip_alphas = torch.sqrt(1.0 / alphas)\n",
        "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
        "posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of dataset: 60000\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "import os\n",
        "train_dir = './mnist'\n",
        "data_list = sorted(glob.glob(os.path.join(train_dir,'*png')))\n",
        "print('Number of dataset:',len(data_list))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vt6JSKawk7_b"
      },
      "source": [
        "Let's test it on our dataset ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(self, transform, root='./mnist' ):\n",
        "        self.paths = sorted(glob.glob(os.path.join(root, \"*.png\")))\n",
        "        print(\"number of training data: \", len(self.paths))\n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img = Image.open(self.paths[idx])\n",
        "        img = self.transform(img)\n",
        "        #print(\"imag size\",img.shape)\n",
        "\n",
        "        return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uuckjpW_k1LN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of training data:  60000\n"
          ]
        }
      ],
      "source": [
        "from torchvision import transforms \n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "\n",
        "IMG_SIZE = 28\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "def load_transformed_dataset():\n",
        "    data_transforms = [\n",
        "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(), # Scales data into [0,1] \n",
        "        transforms.Lambda(lambda t: (t * 2) - 1) # Scale between [-1, 1] \n",
        "    ]\n",
        "    data_transform = transforms.Compose(data_transforms)\n",
        "\n",
        "    dataset = Dataset(transform=data_transform)\n",
        "\n",
        "    return dataset\n",
        "def show_tensor_image(image):\n",
        "    reverse_transforms = transforms.Compose([\n",
        "        transforms.Lambda(lambda t: (t + 1) / 2),\n",
        "        transforms.Lambda(lambda t: t.permute(1, 2, 0)), # CHW to HWC\n",
        "        transforms.Lambda(lambda t: t * 255.),\n",
        "        transforms.Lambda(lambda t: t.numpy().astype(np.uint8)),\n",
        "        transforms.ToPILImage(),\n",
        "    ])\n",
        "\n",
        "    # Take first image of batch\n",
        "    if len(image.shape) == 4:\n",
        "        image = image[0, :, :, :] \n",
        "    #print(\"image size \", reverse_transforms(image).size)\n",
        "    plt.imshow(reverse_transforms(image))\n",
        "    return reverse_transforms(image)\n",
        "\n",
        "data = load_transformed_dataset()\n",
        "dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True,num_workers=16)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116
        },
        "id": "2fUPyJghdoUA",
        "outputId": "0a71ca76-dc54-481f-b845-0409e37d2f68"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2320393/1217489402.py:11: MatplotlibDeprecationWarning: Auto-removal of overlapping axes is deprecated since 3.6 and will be removed two minor releases later; explicitly call ax.remove() as needed.\n",
            "  plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x1500 with 10 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Simulate forward diffusion\n",
        "image = next(iter(dataloader))[0]\n",
        "\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.axis('off')\n",
        "num_images = 10\n",
        "stepsize = int(T/num_images)\n",
        "\n",
        "for idx in range(0, T, stepsize):\n",
        "    t = torch.Tensor([idx]).type(torch.int64)\n",
        "    plt.subplot(1, num_images+1, int(idx/stepsize) + 1)\n",
        "    image, noise = forward_diffusion_sample(image, t)\n",
        "    show_tensor_image(image)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "buW6BaNga-XH"
      },
      "source": [
        "## Step 2: The backward process = U-Net\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYw6u0nJXIWy"
      },
      "source": [
        "For a great introduction to UNets, have a look at this post: https://amaarora.github.io/2020/09/13/unet.html.\n",
        "\n",
        "\n",
        "**Key Takeaways**:\n",
        "- We use a simple form of a UNet for to predict the noise in the image\n",
        "- The input is a noisy image, the ouput the noise in the image\n",
        "- Because the parameters are shared accross time, we need to tell the network in which timestep we are\n",
        "- The Timestep is encoded by the transformer Sinusoidal Embedding\n",
        "- We output one single value (mean), because the variance is fixed\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOYPSxPf_LL7",
        "outputId": "54827b7e-b9c1-4ee5-d6da-07ec7d0e8af2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num params:  3692003\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SimpleUnet(\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPositionEmbeddings()\n",
              "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
              "    (2): ReLU()\n",
              "  )\n",
              "  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (downs): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n",
              "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (transform): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=256, bias=True)\n",
              "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (transform): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bnorm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=128, bias=True)\n",
              "      (conv1): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (transform): ConvTranspose2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bnorm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "    (1): Block(\n",
              "      (time_mlp): Linear(in_features=32, out_features=64, bias=True)\n",
              "      (conv1): Conv2d(256, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (transform): ConvTranspose2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (bnorm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (bnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (relu): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (output): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from torch import nn\n",
        "import math\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, time_emb_dim, up=False):\n",
        "        super().__init__()\n",
        "        self.time_mlp =  nn.Linear(time_emb_dim, out_ch)\n",
        "        if up:\n",
        "            self.conv1 = nn.Conv2d(2*in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.ConvTranspose2d(out_ch, out_ch, 4, 2, 1)\n",
        "        else:\n",
        "            self.conv1 = nn.Conv2d(in_ch, out_ch, 3, padding=1)\n",
        "            self.transform = nn.Conv2d(out_ch, out_ch, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, 3, padding=1)\n",
        "        self.bnorm1 = nn.BatchNorm2d(out_ch)\n",
        "        self.bnorm2 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu  = nn.ReLU()\n",
        "        \n",
        "    def forward(self, x, t, ):\n",
        "        # First Conv\n",
        "        h = self.bnorm1(self.relu(self.conv1(x)))\n",
        "        # Time embedding\n",
        "        time_emb = self.relu(self.time_mlp(t))\n",
        "        # Extend last 2 dimensions\n",
        "        time_emb = time_emb[(..., ) + (None, ) * 2]\n",
        "        # Add time channel\n",
        "        h = h + time_emb\n",
        "        # Second Conv\n",
        "        h = self.bnorm2(self.relu(self.conv2(h)))\n",
        "        # Down or Upsample\n",
        "        return self.transform(h)\n",
        "\n",
        "\n",
        "class SinusoidalPositionEmbeddings(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, time):\n",
        "        device = time.device\n",
        "        half_dim = self.dim // 2\n",
        "        embeddings = math.log(10000) / (half_dim - 1)\n",
        "        embeddings = torch.exp(torch.arange(half_dim, device=device) * -embeddings)\n",
        "        embeddings = time[:, None] * embeddings[None, :]\n",
        "        embeddings = torch.cat((embeddings.sin(), embeddings.cos()), dim=-1)\n",
        "        # TODO: Double check the ordering here\n",
        "        return embeddings\n",
        "\n",
        "\n",
        "class SimpleUnet(nn.Module):\n",
        "    \"\"\"\n",
        "    A simplified variant of the Unet architecture.\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        image_channels = 3\n",
        "        down_channels = (64, 128, 256)\n",
        "        up_channels = (256, 128, 64)\n",
        "        out_dim = 1 \n",
        "        time_emb_dim = 32\n",
        "\n",
        "        # Time embedding\n",
        "        self.time_mlp = nn.Sequential(\n",
        "                SinusoidalPositionEmbeddings(time_emb_dim),\n",
        "                nn.Linear(time_emb_dim, time_emb_dim),\n",
        "                nn.ReLU()\n",
        "            )\n",
        "        \n",
        "        # Initial projection\n",
        "        self.conv0 = nn.Conv2d(image_channels, down_channels[0], 3, padding=1)\n",
        "\n",
        "        # Downsample\n",
        "        self.downs = nn.ModuleList([Block(down_channels[i], down_channels[i+1], \\\n",
        "                                    time_emb_dim) \\\n",
        "                    for i in range(len(down_channels)-1)])\n",
        "        # Upsample\n",
        "        self.ups = nn.ModuleList([Block(up_channels[i], up_channels[i+1], \\\n",
        "                                        time_emb_dim, up=True) \\\n",
        "                    for i in range(len(up_channels)-1)])\n",
        "\n",
        "        self.output = nn.Conv2d(up_channels[-1], 3, out_dim)\n",
        "\n",
        "    def forward(self, x, timestep):\n",
        "        # Embedd time\n",
        "        t = self.time_mlp(timestep)\n",
        "        # Initial conv\n",
        "        x = self.conv0(x)\n",
        "        # Unet\n",
        "        residual_inputs = []\n",
        "        for down in self.downs:\n",
        "            x = down(x, t)\n",
        "            #print(\"x shape\",x.shape)\n",
        "            residual_inputs.append(x)\n",
        "        for up in self.ups:\n",
        "            residual_x = residual_inputs.pop()\n",
        "            #print(residual_x.shape)\n",
        "            # Add residual x as additional channels\n",
        "            x = torch.cat((x, residual_x), dim=1)           \n",
        "            x = up(x, t)\n",
        "        return self.output(x)\n",
        "\n",
        "model = SimpleUnet().to(device)\n",
        "x = torch.randn((1,3,28,28)).to(device)\n",
        "t = torch.randint(0, T, (1,)).long().to(device)\n",
        "model(x,t)\n",
        "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
        "model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tNzccxqWilM"
      },
      "source": [
        "\n",
        "**Further improvements that can be implemented:**\n",
        "- Residual connections\n",
        "- Different activation functions like SiLU, GWLU, ...\n",
        "- BatchNormalization \n",
        "- GroupNormalization\n",
        "- Attention\n",
        "- ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B9GlZrotBXy"
      },
      "source": [
        "## Step 3: The loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph05t8MxXMoY"
      },
      "source": [
        "**Key Takeaways:**\n",
        "- After some maths we end up with a very simple loss function\n",
        "- There are other possible choices like L2 loss ect.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Ed12NNXPtDon"
      },
      "outputs": [],
      "source": [
        "def get_loss(model, x_0, t):\n",
        "    x_noisy, noise = forward_diffusion_sample(x_0, t, device)\n",
        "    noise_pred = model(x_noisy, t)\n",
        "    return F.l1_loss(noise, noise_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7AZkYjKgQTm"
      },
      "source": [
        "## Sampling\n",
        "- Without adding @torch.no_grad() we quickly run out of memory, because pytorch tacks all the previous images for gradient calculation \n",
        "- Because we pre-calculated the noise variances for the forward pass, we also have to use them when we sequentially perform the backward process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "k13hj2mciCHA"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def sample_timestep(x, t):\n",
        "    \"\"\"\n",
        "    Calls the model to predict the noise in the image and returns \n",
        "    the denoised image. \n",
        "    Applies noise to this image, if we are not in the last step yet.\n",
        "    \"\"\"\n",
        "    #print(x.device)\n",
        "    #print(t.device)\n",
        "    betas_t = get_index_from_list(betas, t, x.shape)\n",
        "    #print(\"a\")\n",
        "    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(\n",
        "        sqrt_one_minus_alphas_cumprod, t, x.shape\n",
        "    )\n",
        "    #print(\"b\")\n",
        "    sqrt_recip_alphas_t = get_index_from_list(sqrt_recip_alphas, t, x.shape)\n",
        "    #print(\"c\")\n",
        "    # Call model (current image - noise prediction)\n",
        "    model_mean = sqrt_recip_alphas_t * (\n",
        "        x - betas_t * model(x, t) / sqrt_one_minus_alphas_cumprod_t\n",
        "    )\n",
        "    #print(\"d\")\n",
        "    posterior_variance_t = get_index_from_list(posterior_variance, t, x.shape)\n",
        "    \n",
        "    if t == 0:\n",
        "        return model_mean\n",
        "    else:\n",
        "        noise = torch.randn_like(x)\n",
        "        return model_mean + torch.sqrt(posterior_variance_t) * noise \n",
        "\n",
        "@torch.no_grad()\n",
        "def sample_plot_image():\n",
        "    # Sample noise\n",
        "    img_size = IMG_SIZE\n",
        "    img = torch.randn((1, 3, img_size, img_size), device=device)\n",
        "    #print(img.shape)\n",
        "\n",
        "    plt.figure(figsize=(15,15))\n",
        "    plt.axis('off')\n",
        "    num_images = 8\n",
        "    stepsize = int(T/num_images)\n",
        "\n",
        "    for i in range(0,T)[::-1]:\n",
        "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
        "        print(t)\n",
        "        img = sample_timestep(img, t)\n",
        "        if i % stepsize == 0:\n",
        "            plt.subplot(1, num_images, int(i/stepsize+1))\n",
        "            show_tensor_image(img.detach().cpu())\n",
        "    plt.show()            \n",
        "    return img\n",
        "\n",
        "@torch.no_grad()\n",
        "def test():\n",
        "    # Sample noise\n",
        "    img_size = IMG_SIZE\n",
        "    img = torch.randn((1, 3, img_size, img_size), device=device)\n",
        "    #plt.figure(figsize=(15,15))\n",
        "    #plt.axis('off')\n",
        "    num_images = 1000\n",
        "    t = torch.full((1,), 0, device=device, dtype=torch.long)\n",
        "    #stepsize = int(T/num_images)\n",
        "    imgs = []\n",
        "    for i in range(num_images):\n",
        "        imgs.append(sample_timestep(img, t))\n",
        "    FID = get_fid(imgs, './mnist.npz')\n",
        "                \n",
        "    return FID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIc33L9-uK4q"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bpN_LKYwuLx0",
        "outputId": "297f1c2c-4548-4e0a-84b6-7f6cd6234875"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|                                                             | 0/468 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|▏                                    | 3/468 [00:07<15:02,  1.94s/it, loss_b: 0.7126]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   1%|▌                                    | 7/468 [00:07<04:32,  1.69it/s, loss_b: 0.5913]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   2%|▊                                   | 11/468 [00:07<02:06,  3.62it/s, loss_b: 0.4672]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   3%|█                                   | 13/468 [00:08<01:34,  4.84it/s, loss_b: 0.4307]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|█▎                                  | 17/468 [00:08<00:59,  7.53it/s, loss_b: 0.4042]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   4%|█▌                                  | 21/468 [00:08<00:43, 10.38it/s, loss_b: 0.3504]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   5%|█▊                                  | 24/468 [00:08<00:34, 12.75it/s, loss_b: 0.3375]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|██▏                                 | 28/468 [00:09<00:32, 13.42it/s, loss_b: 0.3026]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   6%|██▎                                 | 30/468 [00:09<00:32, 13.29it/s, loss_b: 0.2911]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   7%|██▌                                 | 34/468 [00:09<00:30, 14.05it/s, loss_b: 0.2770]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   8%|██▉                                 | 38/468 [00:09<00:29, 14.46it/s, loss_b: 0.2671]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|███                                 | 40/468 [00:09<00:30, 14.21it/s, loss_b: 0.2447]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   9%|███▍                                | 44/468 [00:10<00:29, 14.20it/s, loss_b: 0.2406]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  10%|███▋                                | 48/468 [00:10<00:26, 15.98it/s, loss_b: 0.2969]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  11%|███▊                                | 50/468 [00:10<00:27, 15.48it/s, loss_b: 0.3173]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|████▏                               | 54/468 [00:10<00:27, 14.88it/s, loss_b: 0.3174]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  12%|████▍                               | 58/468 [00:11<00:27, 15.04it/s, loss_b: 0.3031]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n",
            "torch.Size([128])\n",
            "torch.Size([128, 3, 28, 28])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:  13%|████▌                               | 59/468 [00:11<01:18,  5.21it/s, loss_b: 0.3031]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn [14], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m   running_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_b\n\u001b[1;32m     21\u001b[0m   optimizer\u001b[39m.\u001b[39mstep()\n\u001b[0;32m---> 22\u001b[0m   pbar\u001b[39m.\u001b[39mset_postfix_str(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mloss_b: \u001b[39m\u001b[39m{\u001b[39;00mloss_b\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m   pbar\u001b[39m.\u001b[39mupdate(\u001b[39m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m loss \u001b[39m=\u001b[39m running_loss\u001b[39m/\u001b[39m\u001b[39mfloat\u001b[39m(len_train_data)\n",
            "File \u001b[0;32m~/CCBDA/HW3/CCBDA_HW3env/lib/python3.8/site-packages/torch/_tensor.py:857\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    855\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, format_spec)\n\u001b[1;32m    856\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[0;32m--> 857\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[1;32m    858\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(\u001b[39mself\u001b[39m, format_spec)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "optimizer = Adam(model.parameters(), lr=0.001)\n",
        "epochs = 100 # Try more!\n",
        "len_train_data = len(dataloader)\n",
        "for epoch in range(epochs):\n",
        "    running_loss = 0.0\n",
        "    with tqdm(total=len_train_data, ncols=100, position=0, leave=True, desc=\"Training: \") as pbar:\n",
        "      for step, batch in enumerate(dataloader):\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        t = torch.randint(0, T, (BATCH_SIZE,), device=device).long()\n",
        "        print(t.shape)\n",
        "        print(batch.shape)\n",
        "        loss_b = get_loss(model, batch, t)\n",
        "        loss_b.backward()\n",
        "        running_loss += loss_b\n",
        "        optimizer.step()\n",
        "        pbar.set_postfix_str(f\"loss_b: {loss_b:.4f}\")\n",
        "        pbar.update(1)\n",
        "      loss = running_loss/float(len_train_data)\n",
        "\n",
        "    if epoch % 5 == 0 and step == 0:\n",
        "      print(f\"Epoch {epoch} | step {step:03d} Loss: {loss.item()} \")\n",
        "      sample_plot_image()\n",
        "    \n",
        "    print(\", \".join([\n",
        "            f\"Epoch {epoch:3d}/{args.epochs:3d}\",\n",
        "            f\"train_loss: {loss:.4f}\",\n",
        "            f\"val_loss: {val_loss:.4f}\",\n",
        "            f\"test_acc: {acc:.4f}\",\n",
        "            f\"lr: {current_lr}\"\n",
        "        ]))\n",
        "      "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "25753.156752750958"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def test(model, device, IMG_SIZE, betas, sqrt_one_minus_alphas_cumprod, sqrt_recip_alphas,posterior_variance):\n",
        "    # Sample noise\n",
        "    img_size = IMG_SIZE\n",
        "    \n",
        "    #plt.figure(figsize=(15,15))\n",
        "    #plt.axis('off')\n",
        "    num_images = 2\n",
        "    #t = torch.full((1,), 0, device=device, dtype=torch.long)\n",
        "    #stepsize = int(T/num_images)\n",
        "    \n",
        "    imgs = torch.randn((2, 3, img_size, img_size), device=device)\n",
        "        \n",
        "        #print(imgs.shape)\n",
        "    for i in range(0,T)[::-1]:\n",
        "        t = torch.full((1,), i, device=device, dtype=torch.long)\n",
        "        #print(model(img,t).shape)\n",
        "        imgs = sample_timestep(imgs, t)\n",
        "\n",
        "        #print(t.device)\n",
        "        #print(img.shape)\n",
        "        #print(t.shape)\n",
        "        #imgs.append(img)\n",
        "        #print(img_output.shape)\n",
        "        #print(sample_timestep(img, t).device)\n",
        "    #imgs = torch.stack(imgs, dim=0)\n",
        "    FID = get_fid(imgs, './mnist.npz',device=device, use_torch=True)\n",
        "                \n",
        "    return FID\n",
        "#device = \"cuda:3\"\n",
        "test(model, device, IMG_SIZE, betas, sqrt_one_minus_alphas_cumprod, sqrt_recip_alphas,posterior_variance)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[NbConvertApp] Converting notebook diffusion_model.ipynb to script\n",
            "[NbConvertApp] Writing 14922 bytes to diffusion_model.py\n"
          ]
        }
      ],
      "source": [
        "!jupyter nbconvert --to script diffusion_model.ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwaGZBrvdJSa"
      },
      "source": [
        "In Table 2, we show the sample quality effects of reverse process parameterizations and training\n",
        "objectives (Section 3.2). We find that the baseline option of predicting µ˜ works well only when\n",
        "trained on the true variational bound instead of unweighted mean squared error, a simplified objective\n",
        "akin to Eq. (14). We also see that learning reverse process variances (by incorporating a parameterized\n",
        "diagonal Σθ(xt) into the variational bound) leads to unstable training and poorer sample quality\n",
        "compared to fixed variances. Predicting \u000f, as we proposed, performs approximately as well as\n",
        "predicting µ˜ when trained on the variational bound with fixed variances, but much better when trained\n",
        "with our simplified objective.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VMKaY1SSfjHA"
      },
      "source": [
        "iffusion models scale down the data with each forward process step (by a √\n",
        "1 − βt factor)\n",
        "so that variance does not grow when adding noise, thus providing consistently scaled inputs\n",
        "to the neural net reverse process. NCSN omits this scaling factor.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QEwOXsxCdJtU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([5, 3, 28, 28])\n",
            "torch.Size([10, 3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "ab = torch.tensor([])\n",
        "a = torch.randn((5,3,28,28))\n",
        "b = torch.randn((5,3,28,28))\n",
        "c = torch.randn((5,3,28,28))\n",
        "ab = torch.cat((ab,a))\n",
        "abc = torch.cat((ab,c))\n",
        "print(ab.shape)\n",
        "print(abc.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "import copy\n",
        "from pathlib import Path\n",
        "from random import random\n",
        "from functools import partial\n",
        "from collections import namedtuple\n",
        "from multiprocessing import cpu_count\n",
        "\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from torch.optim import Adam\n",
        "from torchvision import transforms as T, utils\n",
        "\n",
        "from einops import rearrange, reduce\n",
        "from einops.layers.torch import Rearrange\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm.auto import tqdm\n",
        "#from ema_pytorch import EMA\n",
        "\n",
        "#from accelerate import Accelerator\n",
        "\n",
        "#from denoising_diffusion_pytorch.version import __version__\n",
        "\n",
        "# constants\n",
        "\n",
        "ModelPrediction =  namedtuple('ModelPrediction', ['pred_noise', 'pred_x_start'])\n",
        "\n",
        "# helpers functions\n",
        "\n",
        "def exists(x):\n",
        "    return x is not None\n",
        "\n",
        "def default(val, d):\n",
        "    if exists(val):\n",
        "        return val\n",
        "    return d() if callable(d) else d\n",
        "\n",
        "def identity(t, *args, **kwargs):\n",
        "    return t\n",
        "\n",
        "def cycle(dl):\n",
        "    while True:\n",
        "        for data in dl:\n",
        "            yield data\n",
        "\n",
        "def has_int_squareroot(num):\n",
        "    return (math.sqrt(num) ** 2) == num\n",
        "\n",
        "def num_to_groups(num, divisor):\n",
        "    groups = num // divisor\n",
        "    remainder = num % divisor\n",
        "    arr = [divisor] * groups\n",
        "    if remainder > 0:\n",
        "        arr.append(remainder)\n",
        "    return arr\n",
        "\n",
        "def convert_image_to_fn(img_type, image):\n",
        "    if image.mode != img_type:\n",
        "        return image.convert(img_type)\n",
        "    return image\n",
        "\n",
        "# normalization functions\n",
        "\n",
        "def normalize_to_neg_one_to_one(img):\n",
        "    return img * 2 - 1\n",
        "\n",
        "def unnormalize_to_zero_to_one(t):\n",
        "    return (t + 1) * 0.5\n",
        "\n",
        "# small helper modules\n",
        "\n",
        "class Residual(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, *args, **kwargs):\n",
        "        return self.fn(x, *args, **kwargs) + x\n",
        "\n",
        "def Upsample(dim, dim_out = None):\n",
        "    return nn.Sequential(\n",
        "        nn.Upsample(scale_factor = 2, mode = 'nearest'),\n",
        "        nn.Conv2d(dim, default(dim_out, dim), 3, padding = 1)\n",
        "    )\n",
        "\n",
        "def Downsample(dim, dim_out = None):\n",
        "    return nn.Sequential(\n",
        "        Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1 = 2, p2 = 2),\n",
        "        nn.Conv2d(dim * 4, default(dim_out, dim), 1)\n",
        "    )\n",
        "\n",
        "class WeightStandardizedConv2d(nn.Conv2d):\n",
        "    \"\"\"\n",
        "    https://arxiv.org/abs/1903.10520\n",
        "    weight standardization purportedly works synergistically with group normalization\n",
        "    \"\"\"\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "\n",
        "        weight = self.weight\n",
        "        mean = reduce(weight, 'o ... -> o 1 1 1', 'mean')\n",
        "        var = reduce(weight, 'o ... -> o 1 1 1', partial(torch.var, unbiased = False))\n",
        "        normalized_weight = (weight - mean) * (var + eps).rsqrt()\n",
        "\n",
        "        return F.conv2d(x, normalized_weight, self.bias, self.stride, self.padding, self.dilation, self.groups)\n",
        "\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.g = nn.Parameter(torch.ones(1, dim, 1, 1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        eps = 1e-5 if x.dtype == torch.float32 else 1e-3\n",
        "        var = torch.var(x, dim = 1, unbiased = False, keepdim = True)\n",
        "        mean = torch.mean(x, dim = 1, keepdim = True)\n",
        "        return (x - mean) * (var + eps).rsqrt() * self.g\n",
        "\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = LayerNorm(dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.norm(x)\n",
        "        return self.fn(x)\n",
        "\n",
        "# sinusoidal positional embeds\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "class RandomOrLearnedSinusoidalPosEmb(nn.Module):\n",
        "    \"\"\" following @crowsonkb 's lead with random (learned optional) sinusoidal pos emb \"\"\"\n",
        "    \"\"\" https://github.com/crowsonkb/v-diffusion-jax/blob/master/diffusion/models/danbooru_128.py#L8 \"\"\"\n",
        "\n",
        "    def __init__(self, dim, is_random = False):\n",
        "        super().__init__()\n",
        "        assert (dim % 2) == 0\n",
        "        half_dim = dim // 2\n",
        "        self.weights = nn.Parameter(torch.randn(half_dim), requires_grad = not is_random)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = rearrange(x, 'b -> b 1')\n",
        "        freqs = x * rearrange(self.weights, 'd -> 1 d') * 2 * math.pi\n",
        "        fouriered = torch.cat((freqs.sin(), freqs.cos()), dim = -1)\n",
        "        fouriered = torch.cat((x, fouriered), dim = -1)\n",
        "        return fouriered\n",
        "\n",
        "# building block modules\n",
        "\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, dim, dim_out, groups = 8):\n",
        "        super().__init__()\n",
        "        self.proj = WeightStandardizedConv2d(dim, dim_out, 3, padding = 1)\n",
        "        self.norm = nn.GroupNorm(groups, dim_out)\n",
        "        self.act = nn.SiLU()\n",
        "\n",
        "    def forward(self, x, scale_shift = None):\n",
        "        x = self.proj(x)\n",
        "        x = self.norm(x)\n",
        "\n",
        "        if exists(scale_shift):\n",
        "            scale, shift = scale_shift\n",
        "            x = x * (scale + 1) + shift\n",
        "\n",
        "        x = self.act(x)\n",
        "        return x\n",
        "\n",
        "class ResnetBlock(nn.Module):\n",
        "    def __init__(self, dim, dim_out, *, time_emb_dim = None, groups = 8):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(time_emb_dim, dim_out * 2)\n",
        "        ) if exists(time_emb_dim) else None\n",
        "\n",
        "        self.block1 = Block(dim, dim_out, groups = groups)\n",
        "        self.block2 = Block(dim_out, dim_out, groups = groups)\n",
        "        self.res_conv = nn.Conv2d(dim, dim_out, 1) if dim != dim_out else nn.Identity()\n",
        "\n",
        "    def forward(self, x, time_emb = None):\n",
        "\n",
        "        scale_shift = None\n",
        "        if exists(self.mlp) and exists(time_emb):\n",
        "            time_emb = self.mlp(time_emb)\n",
        "            time_emb = rearrange(time_emb, 'b c -> b c 1 1')\n",
        "            scale_shift = time_emb.chunk(2, dim = 1)\n",
        "\n",
        "        h = self.block1(x, scale_shift = scale_shift)\n",
        "\n",
        "        h = self.block2(h)\n",
        "\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "class LinearAttention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
        "\n",
        "        self.to_out = nn.Sequential(\n",
        "            nn.Conv2d(hidden_dim, dim, 1),\n",
        "            LayerNorm(dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
        "\n",
        "        q = q.softmax(dim = -2)\n",
        "        k = k.softmax(dim = -1)\n",
        "\n",
        "        q = q * self.scale\n",
        "        v = v / (h * w)\n",
        "\n",
        "        context = torch.einsum('b h d n, b h e n -> b h d e', k, v)\n",
        "\n",
        "        out = torch.einsum('b h d e, b h d n -> b h e n', context, q)\n",
        "        out = rearrange(out, 'b h c (x y) -> b (h c) x y', h = self.heads, x = h, y = w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, dim, heads = 4, dim_head = 32):\n",
        "        super().__init__()\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        hidden_dim = dim_head * heads\n",
        "\n",
        "        self.to_qkv = nn.Conv2d(dim, hidden_dim * 3, 1, bias = False)\n",
        "        self.to_out = nn.Conv2d(hidden_dim, dim, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, c, h, w = x.shape\n",
        "        qkv = self.to_qkv(x).chunk(3, dim = 1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b (h c) x y -> b h c (x y)', h = self.heads), qkv)\n",
        "\n",
        "        q = q * self.scale\n",
        "\n",
        "        sim = einsum('b h d i, b h d j -> b h i j', q, k)\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        out = einsum('b h i j, b h d j -> b h i d', attn, v)\n",
        "\n",
        "        out = rearrange(out, 'b h (x y) d -> b (h d) x y', x = h, y = w)\n",
        "        return self.to_out(out)\n",
        "\n",
        "# model\n",
        "\n",
        "class Unet(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        dim,\n",
        "        init_dim = None,\n",
        "        out_dim = None,\n",
        "        dim_mults=(1, 2, 4, 8),\n",
        "        channels = 3,\n",
        "        self_condition = False,\n",
        "        resnet_block_groups = 8,\n",
        "        learned_variance = False,\n",
        "        learned_sinusoidal_cond = False,\n",
        "        random_fourier_features = False,\n",
        "        learned_sinusoidal_dim = 16\n",
        "    ):\n",
        "        super().__init__()\n",
        "\n",
        "        # determine dimensions\n",
        "\n",
        "        self.channels = channels\n",
        "        self.self_condition = self_condition\n",
        "        input_channels = channels * (2 if self_condition else 1)\n",
        "\n",
        "        init_dim = default(init_dim, dim)\n",
        "        self.init_conv = nn.Conv2d(input_channels, init_dim, 7, padding = 3)\n",
        "\n",
        "        dims = [init_dim, *map(lambda m: dim * m, dim_mults)]\n",
        "        in_out = list(zip(dims[:-1], dims[1:]))\n",
        "\n",
        "        block_klass = partial(ResnetBlock, groups = resnet_block_groups)\n",
        "\n",
        "        # time embeddings\n",
        "\n",
        "        time_dim = dim * 4\n",
        "\n",
        "        self.random_or_learned_sinusoidal_cond = learned_sinusoidal_cond or random_fourier_features\n",
        "\n",
        "        if self.random_or_learned_sinusoidal_cond:\n",
        "            sinu_pos_emb = RandomOrLearnedSinusoidalPosEmb(learned_sinusoidal_dim, random_fourier_features)\n",
        "            fourier_dim = learned_sinusoidal_dim + 1\n",
        "        else:\n",
        "            sinu_pos_emb = SinusoidalPosEmb(dim)\n",
        "            fourier_dim = dim\n",
        "\n",
        "        self.time_mlp = nn.Sequential(\n",
        "            sinu_pos_emb,\n",
        "            nn.Linear(fourier_dim, time_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(time_dim, time_dim)\n",
        "        )\n",
        "\n",
        "        # layers\n",
        "\n",
        "        self.downs = nn.ModuleList([])\n",
        "        self.ups = nn.ModuleList([])\n",
        "        num_resolutions = len(in_out)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (num_resolutions - 1)\n",
        "\n",
        "            self.downs.append(nn.ModuleList([\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                block_klass(dim_in, dim_in, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_in, LinearAttention(dim_in))),\n",
        "                Downsample(dim_in, dim_out) if not is_last else nn.Conv2d(dim_in, dim_out, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "        mid_dim = dims[-1]\n",
        "        self.mid_block1 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "        self.mid_attn = Residual(PreNorm(mid_dim, Attention(mid_dim)))\n",
        "        self.mid_block2 = block_klass(mid_dim, mid_dim, time_emb_dim = time_dim)\n",
        "\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out)):\n",
        "            is_last = ind == (len(in_out) - 1)\n",
        "\n",
        "            self.ups.append(nn.ModuleList([\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                block_klass(dim_out + dim_in, dim_out, time_emb_dim = time_dim),\n",
        "                Residual(PreNorm(dim_out, LinearAttention(dim_out))),\n",
        "                Upsample(dim_out, dim_in) if not is_last else  nn.Conv2d(dim_out, dim_in, 3, padding = 1)\n",
        "            ]))\n",
        "\n",
        "        default_out_dim = channels * (1 if not learned_variance else 2)\n",
        "        self.out_dim = default(out_dim, default_out_dim)\n",
        "\n",
        "        self.final_res_block = block_klass(dim * 2, dim, time_emb_dim = time_dim)\n",
        "        self.final_conv = nn.Conv2d(dim, self.out_dim, 1)\n",
        "\n",
        "    def forward(self, x, time, x_self_cond = None):\n",
        "        if self.self_condition:\n",
        "            x_self_cond = default(x_self_cond, lambda: torch.zeros_like(x))\n",
        "            x = torch.cat((x_self_cond, x), dim = 1)\n",
        "\n",
        "        x = self.init_conv(x)\n",
        "        r = x.clone()\n",
        "\n",
        "        t = self.time_mlp(time)\n",
        "\n",
        "        h = []\n",
        "\n",
        "        for block1, block2, attn, downsample in self.downs:\n",
        "            x = block1(x, t)\n",
        "            h.append(x)\n",
        "\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "            h.append(x)\n",
        "\n",
        "            x = downsample(x)\n",
        "\n",
        "        x = self.mid_block1(x, t)\n",
        "        x = self.mid_attn(x)\n",
        "        x = self.mid_block2(x, t)\n",
        "\n",
        "        for block1, block2, attn, upsample in self.ups:\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block1(x, t)\n",
        "\n",
        "            x = torch.cat((x, h.pop()), dim = 1)\n",
        "            x = block2(x, t)\n",
        "            x = attn(x)\n",
        "\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = torch.cat((x, r), dim = 1)\n",
        "\n",
        "        x = self.final_res_block(x, t)\n",
        "        return self.final_conv(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 3, 28, 28])\n",
            "Num params:  9901699\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Unet(\n",
              "  (init_conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))\n",
              "  (time_mlp): Sequential(\n",
              "    (0): SinusoidalPosEmb()\n",
              "    (1): Linear(in_features=64, out_features=256, bias=True)\n",
              "    (2): GELU(approximate='none')\n",
              "    (3): Linear(in_features=256, out_features=256, bias=True)\n",
              "  )\n",
              "  (downs): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n",
              "        (1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Rearrange('b c (h p1) (w p2) -> b (c p1 p2) h w', p1=2, p2=2)\n",
              "        (1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (2): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Identity()\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (ups): ModuleList(\n",
              "    (0): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        (1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (1): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=256, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(192, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(128, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Sequential(\n",
              "        (0): Upsample(scale_factor=2.0, mode=nearest)\n",
              "        (1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (2): ModuleList(\n",
              "      (0): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (1): ResnetBlock(\n",
              "        (mlp): Sequential(\n",
              "          (0): SiLU()\n",
              "          (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "        )\n",
              "        (block1): Block(\n",
              "          (proj): WeightStandardizedConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (block2): Block(\n",
              "          (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "          (act): SiLU()\n",
              "        )\n",
              "        (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (2): Residual(\n",
              "        (fn): PreNorm(\n",
              "          (fn): LinearAttention(\n",
              "            (to_qkv): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (to_out): Sequential(\n",
              "              (0): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "              (1): LayerNorm()\n",
              "            )\n",
              "          )\n",
              "          (norm): LayerNorm()\n",
              "        )\n",
              "      )\n",
              "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    )\n",
              "  )\n",
              "  (mid_block1): ResnetBlock(\n",
              "    (mlp): Sequential(\n",
              "      (0): SiLU()\n",
              "      (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "    )\n",
              "    (block1): Block(\n",
              "      (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (block2): Block(\n",
              "      (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (res_conv): Identity()\n",
              "  )\n",
              "  (mid_attn): Residual(\n",
              "    (fn): PreNorm(\n",
              "      (fn): Attention(\n",
              "        (to_qkv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "        (to_out): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      )\n",
              "      (norm): LayerNorm()\n",
              "    )\n",
              "  )\n",
              "  (mid_block2): ResnetBlock(\n",
              "    (mlp): Sequential(\n",
              "      (0): SiLU()\n",
              "      (1): Linear(in_features=256, out_features=512, bias=True)\n",
              "    )\n",
              "    (block1): Block(\n",
              "      (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (block2): Block(\n",
              "      (proj): WeightStandardizedConv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 256, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (res_conv): Identity()\n",
              "  )\n",
              "  (final_res_block): ResnetBlock(\n",
              "    (mlp): Sequential(\n",
              "      (0): SiLU()\n",
              "      (1): Linear(in_features=256, out_features=128, bias=True)\n",
              "    )\n",
              "    (block1): Block(\n",
              "      (proj): WeightStandardizedConv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (block2): Block(\n",
              "      (proj): WeightStandardizedConv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (norm): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
              "      (act): SiLU()\n",
              "    )\n",
              "    (res_conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "  )\n",
              "  (final_conv): Conv2d(64, 3, kernel_size=(1, 1), stride=(1, 1))\n",
              ")"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = Unet(dim = 64,dim_mults = (1,2,4)).to(device)\n",
        "T=1000\n",
        "x = torch.randn((1,3,28,28)).to(device)\n",
        "t = torch.randint(0, T, (1,)).long().to(device)\n",
        "print(model(x,t).shape)\n",
        "print(\"Num params: \", sum(p.numel() for p in model.parameters()))\n",
        "model"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "wLHSIArLcFK0",
        "Rj17psVw7Shg",
        "buW6BaNga-XH",
        "8B9GlZrotBXy",
        "i7AZkYjKgQTm",
        "BIc33L9-uK4q"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "CCBDA_HW3env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
    },
    "vscode": {
      "interpreter": {
        "hash": "6ae799f72a4385797fde21c86378e06ea9254954dab69d368062e58ffff4bf49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
